{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508352c6-9226-400e-b422-b06cc5154a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "latents = latents * self.scheduler.init_noise_sigma\n",
    "        self.scheduler.set_timesteps(num_inference_steps, device=device)\n",
    "        timesteps = self.scheduler.timesteps\n",
    "latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)\n",
    "\n",
    "                # compute the previous noisy sample x_t -> x_t-1\n",
    "                latents = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs).prev_sample\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a963a14-f5cb-47c8-b9db-245a2fef6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# during training\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
    "            timesteps = timesteps.long()\n",
    "            \n",
    "            # Add noise to the latents according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7780cf2e-f610-4bfe-924a-e7102cf31de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler, LMSDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5709d9c-b3e0-477a-abc6-a0f913041a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDDIMScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_train_timesteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_start\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_end\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_schedule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrained_betas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclip_sample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mset_alpha_to_one\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_offset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Denoising diffusion implicit models is a scheduler that extends the denoising procedure introduced in denoising\n",
       "diffusion probabilistic models (DDPMs) with non-Markovian guidance.\n",
       "\n",
       "[`~ConfigMixin`] takes care of storing all config attributes that are passed in the scheduler's `__init__`\n",
       "function, such as `num_train_timesteps`. They can be accessed via `scheduler.config.num_train_timesteps`.\n",
       "[`SchedulerMixin`] provides general loading and saving functionality via the [`SchedulerMixin.save_pretrained`] and\n",
       "[`~SchedulerMixin.from_pretrained`] functions.\n",
       "\n",
       "For more details, see the original paper: https://arxiv.org/abs/2010.02502\n",
       "\n",
       "Args:\n",
       "    num_train_timesteps (`int`): number of diffusion steps used to train the model.\n",
       "    beta_start (`float`): the starting `beta` value of inference.\n",
       "    beta_end (`float`): the final `beta` value.\n",
       "    beta_schedule (`str`):\n",
       "        the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from\n",
       "        `linear`, `scaled_linear`, or `squaredcos_cap_v2`.\n",
       "    trained_betas (`np.ndarray`, optional):\n",
       "        option to pass an array of betas directly to the constructor to bypass `beta_start`, `beta_end` etc.\n",
       "    clip_sample (`bool`, default `True`):\n",
       "        option to clip predicted sample between -1 and 1 for numerical stability.\n",
       "    set_alpha_to_one (`bool`, default `True`):\n",
       "        each diffusion step uses the value of alphas product at that step and at the previous one. For the final\n",
       "        step there is no previous alpha. When this option is `True` the previous alpha product is fixed to `1`,\n",
       "        otherwise it uses the value of alpha at step 0.\n",
       "    steps_offset (`int`, default `0`):\n",
       "        an offset added to the inference steps. You can use a combination of `offset=1` and\n",
       "        `set_alpha_to_one=False`, to make the last step use step 0 for the previous alpha product, as done in\n",
       "        stable diffusion.\n",
       "    prediction_type (`str`, default `epsilon`, optional):\n",
       "        prediction type of the scheduler function, one of `epsilon` (predicting the noise of the diffusion\n",
       "        process), `sample` (directly predicting the noisy sample`) or `v_prediction` (see section 2.4\n",
       "        https://imagen.research.google/video/paper.pdf)\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/python311/lib/python3.11/site-packages/diffusers/schedulers/scheduling_ddim.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?DDIMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf814207-4695-4aa2-a606-d6fb428632f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddim = DDIMScheduler(num_train_timesteps=1000,\n",
    "                    beta_start=0.00085,\n",
    "                    beta_end=0.012,\n",
    "                    beta_schedule=\"linear\",\n",
    "                    steps_offset=1,\n",
    "                    clip_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49539d76-3605-4291-97de-2e22f80efef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLMSDiscreteScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_train_timesteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_start\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_end\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_schedule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrained_betas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Linear Multistep Scheduler for discrete beta schedules. Based on the original k-diffusion implementation by\n",
       "Katherine Crowson:\n",
       "https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181\n",
       "\n",
       "[`~ConfigMixin`] takes care of storing all config attributes that are passed in the scheduler's `__init__`\n",
       "function, such as `num_train_timesteps`. They can be accessed via `scheduler.config.num_train_timesteps`.\n",
       "[`SchedulerMixin`] provides general loading and saving functionality via the [`SchedulerMixin.save_pretrained`] and\n",
       "[`~SchedulerMixin.from_pretrained`] functions.\n",
       "\n",
       "Args:\n",
       "    num_train_timesteps (`int`): number of diffusion steps used to train the model.\n",
       "    beta_start (`float`): the starting `beta` value of inference.\n",
       "    beta_end (`float`): the final `beta` value.\n",
       "    beta_schedule (`str`):\n",
       "        the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from\n",
       "        `linear` or `scaled_linear`.\n",
       "    trained_betas (`np.ndarray`, optional):\n",
       "        option to pass an array of betas directly to the constructor to bypass `beta_start`, `beta_end` etc.\n",
       "    prediction_type (`str`, default `epsilon`, optional):\n",
       "        prediction type of the scheduler function, one of `epsilon` (predicting the noise of the diffusion\n",
       "        process), `sample` (directly predicting the noisy sample`) or `v_prediction` (see section 2.4\n",
       "        https://imagen.research.google/video/paper.pdf)\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/python311/lib/python3.11/site-packages/diffusers/schedulers/scheduling_lms_discrete.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LMSDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88288a11-56ba-41fb-85a1-589932ab52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b1c310-f533-423c-be64-9cb010ce6159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddim.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a54c4d-6036-4bb9-9b11-2b1b273bae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6146)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12300f76-4646-49e4-80fc-9d981d17e474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mddim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_timesteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference.\n",
       "\n",
       "Args:\n",
       "    num_inference_steps (`int`):\n",
       "        the number of diffusion steps used when generating samples with a pre-trained model.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/python311/lib/python3.11/site-packages/diffusers/schedulers/scheduling_ddim.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?ddim.set_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb860110-70ce-4c23-b6d2-1c87ab30fd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mllms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_timesteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Sets the timesteps used for the diffusion chain. Supporting function to be run before inference.\n",
       "\n",
       "Args:\n",
       "    num_inference_steps (`int`):\n",
       "        the number of diffusion steps used when generating samples with a pre-trained model.\n",
       "    device (`str` or `torch.device`, optional):\n",
       "        the device to which the timesteps should be moved to. If `None`, the timesteps are not moved.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/python311/lib/python3.11/site-packages/diffusers/schedulers/scheduling_lms_discrete.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?llms.set_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dbd5057-1802-4670-829c-9ed445121798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([981, 961, 941, 921, 901, 881, 861, 841, 821, 801, 781, 761, 741, 721,\n",
       "        701, 681, 661, 641, 621, 601, 581, 561, 541, 521, 501, 481, 461, 441,\n",
       "        421, 401, 381, 361, 341, 321, 301, 281, 261, 241, 221, 201, 181, 161,\n",
       "        141, 121, 101,  81,  61,  41,  21,   1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddim.set_timesteps(50)\n",
    "ddim.timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a68423aa-a7f0-48ed-ab53-14b5c51de5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddim.num_inference_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63209109-0d30-4e52-a766-55d52b86a84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddim.num_train_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85baff7b-5950-48a5-9517-78c4a2c0c352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddim.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2504cccb-fe50-4c12-9768-248161122d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mddim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_model_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtimestep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Ensures interchangeability with schedulers that need to scale the denoising model input depending on the\n",
       "current timestep.\n",
       "\n",
       "Args:\n",
       "    sample (`torch.FloatTensor`): input sample\n",
       "    timestep (`int`, optional): current timestep\n",
       "\n",
       "Returns:\n",
       "    `torch.FloatTensor`: scaled input sample\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/python311/lib/python3.11/site-packages/diffusers/schedulers/scheduling_ddim.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?ddim.scale_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b560d77d-8655-4429-9eaa-b5ebc85dd6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.config.num_train_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66c2a26d-c2ec-4a88-96f9-5e082db1f75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([296, 109,  70, 262, 545])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "timesteps = torch.randint(0, 1000, (5, ))\n",
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aec14cd-13dc-4a6c-af2e-326d14f661f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mllms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moriginal_samples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnoise\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtimesteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/python311/lib/python3.11/site-packages/diffusers/schedulers/scheduling_lms_discrete.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?llms.add_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adf42bae-4994-4903-a5df-5915023a5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = torch.randn(5, 4, 64, 64)\n",
    "noise = torch.randn_like(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60960009-5005-4eb4-a123-9ca4566c3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = torch.randint(0, llms.config.num_train_timesteps, (5,))\n",
    "timesteps = timesteps.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83138188-64c4-4a17-b474-07a3870511ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([712, 468, 464, 341, 657])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8afc282b-8737-4bbb-b06d-c2229365d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_latents = llms.add_noise(latents, noise, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04894937-248b-40be-b46c-37ed399de60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14.6146, 14.5263, 14.4386,  ...,  0.0413,  0.0292,  0.0000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms.sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91936e59-c0e1-4451-8aac-e968f590313e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
